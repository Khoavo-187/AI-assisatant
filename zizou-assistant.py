from gtts import gTTS
from google import genai
from google.genai import types
import speech_recognition
import streamlit as st
import tempfile
import os
from PIL import Image
import base64
import io
import wave
import time

# Enhanced page configuration
st.set_page_config(
    page_title="Zizou AI Assistant", 
    page_icon="ü§ñ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# Professional CSS styling
st.markdown("""
<style>
/* Import modern fonts */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

/* Main app styling */
.main {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    min-height: 100vh;
}

/* Custom background overlay */
.stApp {
    background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
    color: white;
}

/* Sidebar styling */
.css-1d391kg {
    background: linear-gradient(180deg, #2c3e50 0%, #34495e 100%);
    border-right: 2px solid #3498db;
}

/* Title styling */
h1 {
    font-family: 'Inter', sans-serif;
    font-weight: 700;
    color: #ffffff;
    text-align: center;
    font-size: 3rem;
    margin-bottom: 1rem;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    background: linear-gradient(45deg, #3498db, #e74c3c);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

/* Subtitle styling */
h3 {
    font-family: 'Inter', sans-serif;
    font-weight: 500;
    color: #ecf0f1;
    text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
}

/* Card-like containers */
.stTabs [data-baseweb="tab-list"] {
    background: rgba(255,255,255,0.1);
    border-radius: 15px;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255,255,255,0.2);
    padding: 8px;
}

.stTabs [data-baseweb="tab"] {
    background: transparent;
    color: #ecf0f1;
    border-radius: 10px;
    font-weight: 500;
    font-family: 'Inter', sans-serif;
}

.stTabs [aria-selected="true"] {
    background: linear-gradient(45deg, #3498db, #2ecc71);
    color: white;
}

/* Button styling */
.stButton button {
    background: linear-gradient(45deg, #3498db, #2ecc71);
    color: white;
    border: none;
    border-radius: 12px;
    font-family: 'Inter', sans-serif;
    font-weight: 500;
    padding: 12px 24px;
    box-shadow: 0 4px 15px rgba(52, 152, 219, 0.3);
    transition: all 0.3s ease;
}

.stButton button:hover {
    background: linear-gradient(45deg, #2980b9, #27ae60);
    box-shadow: 0 6px 20px rgba(52, 152, 219, 0.4);
    transform: translateY(-2px);
}

/* Input fields styling */
.stTextArea textarea, .stTextInput input, .stSelectbox select {
    background: rgba(255,255,255,0.1);
    border: 1px solid rgba(255,255,255,0.3);
    border-radius: 10px;
    color: white;
    backdrop-filter: blur(5px);
    font-family: 'Inter', sans-serif;
}

.stTextArea textarea::placeholder, .stTextInput input::placeholder {
    color: rgba(255,255,255,0.7);
}

/* Success/Error messages */
.stSuccess {
    background: linear-gradient(45deg, #2ecc71, #27ae60);
    border-radius: 10px;
    border: none;
    color: white;
}

.stError {
    background: linear-gradient(45deg, #e74c3c, #c0392b);
    border-radius: 10px;
    border: none;
    color: white;
}

.stInfo {
    background: linear-gradient(45deg, #3498db, #2980b9);
    border-radius: 10px;
    border: none;
    color: white;
}

.stWarning {
    background: linear-gradient(45deg, #f39c12, #e67e22);
    border-radius: 10px;
    border: none;
    color: white;
}

/* File uploader styling */
.stFileUploader {
    background: rgba(255,255,255,0.1);
    border-radius: 15px;
    border: 2px dashed rgba(255,255,255,0.3);
    backdrop-filter: blur(10px);
}

/* Columns styling */
.stColumn {
    background: rgba(255,255,255,0.05);
    border-radius: 15px;
    padding: 20px;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255,255,255,0.1);
    margin: 10px 5px;
}

/* Chat bubble styling */
.user-message {
    background: linear-gradient(45deg, #3498db, #2980b9);
    border-radius: 20px 20px 5px 20px;
    padding: 15px;
    margin: 10px 0;
    color: white;
    max-width: 80%;
    margin-left: auto;
    box-shadow: 0 4px 15px rgba(52, 152, 219, 0.3);
}

.assistant-message {
    background: linear-gradient(45deg, #2ecc71, #27ae60);
    border-radius: 20px 20px 20px 5px;
    padding: 15px;
    margin: 10px 0;
    color: white;
    max-width: 80%;
    box-shadow: 0 4px 15px rgba(46, 204, 113, 0.3);
}

/* Professional status indicators */
.status-online {
    display: inline-block;
    width: 12px;
    height: 12px;
    background: #2ecc71;
    border-radius: 50%;
    animation: pulse 2s infinite;
    margin-right: 8px;
}

@keyframes pulse {
    0% { box-shadow: 0 0 0 0 rgba(46, 204, 113, 0.7); }
    70% { box-shadow: 0 0 0 10px rgba(46, 204, 113, 0); }
    100% { box-shadow: 0 0 0 0 rgba(46, 204, 113, 0); }
}

/* Audio player styling */
.stAudio {
    background: rgba(255,255,255,0.1);
    border-radius: 10px;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255,255,255,0.2);
    padding: 10px;
    margin: 10px 0;
}

/* Voice wave animation */
.voice-wave {
    display: inline-block;
    margin-right: 8px;
}

.voice-wave span {
    display: inline-block;
    width: 4px;
    height: 20px;
    background: #3498db;
    margin: 0 2px;
    animation: wave 1s ease-in-out infinite;
}

.voice-wave span:nth-child(2) { animation-delay: 0.1s; }
.voice-wave span:nth-child(3) { animation-delay: 0.2s; }
.voice-wave span:nth-child(4) { animation-delay: 0.3s; }

@keyframes wave {
    0%, 100% { height: 20px; }
    50% { height: 5px; }
}

/* Enhanced audio player */
.audio-container {
    background: linear-gradient(45deg, rgba(52, 152, 219, 0.1), rgba(46, 204, 113, 0.1));
    border-radius: 15px;
    padding: 20px;
    margin: 15px 0;
    border: 1px solid rgba(255,255,255,0.2);
    backdrop-filter: blur(10px);
}

.download-link {
    background: linear-gradient(45deg, #3498db, #2ecc71);
    color: white;
    padding: 10px 20px;
    border-radius: 10px;
    text-decoration: none;
    font-weight: 500;
    display: inline-block;
    margin: 10px 5px;
    transition: all 0.3s ease;
}

.download-link:hover {
    background: linear-gradient(45deg, #2980b9, #27ae60);
    transform: translateY(-2px);
    box-shadow: 0 4px 15px rgba(52, 152, 219, 0.3);
}
</style>
""", unsafe_allow_html=True)

# Initialize Gemini client
client = genai.Client(
    api_key="AIzaSyDCug_95N5QwzPhF_HqTU7S8KYgJQhDO0Y"
)

# NO PYGAME INITIALIZATION - Fully removed for Streamlit Cloud compatibility
robot_ear = speech_recognition.Recognizer()
robot_brain = "" 

# Enhanced Zizou personality configurations
PERSONALITY_CONFIGS = {
    "professional": {
        "name": "Chuy√™n nghi·ªáp",
        "prompt": """
        T√¥i v·ªõi t∆∞ c√°ch l√† ch·ªß c·ªßa doanh nghi·ªáp qu·∫£n l√≠ c√°t to√†n qu·ªëc (g·ªçi t√¥i l√† l∆∞·ª£m)
        B·∫°n l√† m·ªôt tr·ª£ l√≠ chuy√™n nghi·ªáp c·ªßa t√¥i, th√¥ng minh v√† nhanh nh·∫πn.
        H√£y tr·∫£ l·ªùi m·ªôt c√°ch:
        - Chuy√™n nghi·ªáp v√† ch√≠nh x√°c
        - Bi·∫øt c√°ch di·ªÖn ƒë·∫°t
        - T·ª± tin v√† nhanh ch√≥ng
        - Lu√¥n s·∫µn s√†ng gi√∫p ƒë·ª°
        - Kh·∫£ nƒÉng xoay s·ªü t√¨nh hu·ªëng tuy·ªát v·ªùi, t∆∞ duy h∆°n ng∆∞·ªùi
        
        Khi ƒë∆∞·ª£c cung c·∫•p h√¨nh ·∫£nh ho·∫∑c file, h√£y ph√¢n t√≠ch chi ti·∫øt v√† gi·∫£i th√≠ch m·ªôt c√°ch d·ªÖ hi·ªÉu.
        H√£y b√°o c√°o nh∆∞ 1 tr·ª£ l√≠ chuy√™n nghi·ªáp trong lƒ©nh v·ª±c kinh t·∫ø
        Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
        """
    },
    "friendly": {
        "name": "Th√¢n thi·ªán",
        "prompt": """
        B·∫°n l√† Zizou, m·ªôt AI assistant th√¢n thi·ªán v√† g·∫ßn g≈©i.
        H√£y tr·∫£ l·ªùi v·ªõi phong c√°ch:
        - ·∫§m √°p v√† g·∫ßn g≈©i
        - Nhi·ªát t√¨nh gi√∫p ƒë·ª°
        - D·ªÖ hi·ªÉu v√† ƒë∆°n gi·∫£n
        - C√≥ th·ªÉ s·ª≠ d·ª•ng emoji ph√π h·ª£p
        - Gi·ªçng ƒëi·ªáu tho·∫£i m√°i, kh√¥ng qu√° nghi√™m t√∫c
        
        Lu√¥n s·∫µn s√†ng gi·∫£i th√≠ch v√† h·ªó tr·ª£ ng∆∞·ªùi d√πng.
        Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
        """
    },
    "academic": {
        "name": "H·ªçc thu·∫≠t",
        "prompt": """
        B·∫°n l√† m·ªôt chuy√™n gia h·ªçc thu·∫≠t v·ªõi ki·∫øn th·ª©c s√¢u r·ªông.
        Phong c√°ch tr·∫£ l·ªùi:
        - Chi ti·∫øt v√† c√≥ cƒÉn c·ª©
        - S·ª≠ d·ª•ng thu·∫≠t ng·ªØ chuy√™n m√¥n khi c·∫ßn
        - Ph√¢n t√≠ch s√¢u s·∫Øc
        - ƒê∆∞a ra nhi·ªÅu g√≥c nh√¨n kh√°c nhau
        - Tr√≠ch d·∫´n th√¥ng tin ƒë√°ng tin c·∫≠y
        
        Lu√¥n c·ªë g·∫Øng gi√°o d·ª•c v√† cung c·∫•p th√¥ng tin c√≥ gi√° tr·ªã.
        Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
        """
    },
    "creative": {
        "name": "S√°ng t·∫°o",
        "prompt": """
        B·∫°n l√† m·ªôt AI assistant s√°ng t·∫°o v√† ƒë·∫ßy c·∫£m h·ª©ng.
        Phong c√°ch tr·∫£ l·ªùi:
        - S√°ng t·∫°o v√† ƒë·ªôc ƒë√°o
        - S·ª≠ d·ª•ng ·∫©n d·ª• v√† h√¨nh ·∫£nh sinh ƒë·ªông
        - Khuy·∫øn kh√≠ch t∆∞ duy m·ªõi
        - ƒê∆∞a ra nhi·ªÅu √Ω t∆∞·ªüng kh√°c nhau
        - C√≥ th·ªÉ s·ª≠ d·ª•ng c√¢u chuy·ªán minh h·ªça
        
        Lu√¥n c·ªë g·∫Øng truy·ªÅn c·∫£m h·ª©ng v√† ƒë·ªông l·ª±c.
        Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
        """
    }
}

# Enhanced voice options
VOICE_OPTIONS = {
    "Kore (Gemini TTS)": {
        "model": "gemini-2.5-flash-preview-tts",
        "voice": "Kore",
        "description": "Gi·ªçng n√≥i AI ch·∫•t l∆∞·ª£ng cao, t·ª± nhi√™n"
    },
    "Aoede (Gemini TTS)": {
        "model": "gemini-2.5-flash-preview-tts", 
        "voice": "Aoede",
        "description": "Gi·ªçng n√≥i n·ªØ m∆∞·ª£t m√†, d·ªÖ nghe"
    },
    "Charon (Gemini TTS)": {
        "model": "gemini-2.5-flash-preview-tts",
        "voice": "Charon", 
        "description": "Gi·ªçng n√≥i nam tr·∫ßm ·∫•m"
    },
    "Fenrir (Gemini TTS)": {
        "model": "gemini-2.5-flash-preview-tts",
        "voice": "Fenrir",
        "description": "Gi·ªçng n√≥i nƒÉng ƒë·ªông, m·∫°nh m·∫Ω"
    },
    "Vietnamese (gTTS)": {
        "model": "gtts",
        "voice": "vi",
        "description": "Gi·ªçng ti·∫øng Vi·ªát truy·ªÅn th·ªëng"
    }
}

def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):
    """Helper function to save wave file"""
    with wave.open(filename, "wb") as wf:
        wf.setnchannels(channels)
        wf.setsampwidth(sample_width)
        wf.setframerate(rate)
        wf.writeframes(pcm)

def speak_with_gemini_voice(text, voice_name="Kore", auto_play=True):
    """Enhanced TTS using Gemini's voice options - Streamlit Compatible"""
    try:
        # Clean text for speech
        clean_text = text.replace("*", "").replace("#", "").strip()
        if not clean_text:
            return False, None
            
        # Generate speech using Gemini with selected voice
        response = client.models.generate_content(
            model="gemini-2.5-flash-preview-tts",
            contents=clean_text,
            config=types.GenerateContentConfig(
                response_modalities=["AUDIO"],
                speech_config=types.SpeechConfig(
                    voice_config=types.VoiceConfig(
                        prebuilt_voice_config=types.PrebuiltVoiceConfig(
                            voice_name=voice_name,
                        )
                    )
                ),
            )
        )
        
        # Extract audio data
        audio_data = response.candidates[0].content.parts[0].inline_data.data
        
        if auto_play:
            # Create temporary file and use Streamlit audio player with autoplay
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                wave_file(tmp_file.name, audio_data)
                temp_path = tmp_file.name
            
            # Display audio player with enhanced styling
            st.markdown('<div class="audio-container">', unsafe_allow_html=True)
            st.markdown(f"üéµ **Playing with {voice_name} voice:**")
            
            with open(temp_path, 'rb') as audio_file:
                audio_bytes = audio_file.read()
                st.audio(audio_bytes, format='audio/wav', autoplay=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            # Cleanup
            os.unlink(temp_path)
        
        return True, audio_data
        
    except Exception as e:
        st.error(f"üîä L·ªói ph√°t √¢m thanh v·ªõi {voice_name} voice: {e}")
        # Fallback to gTTS if voice fails
        return speak_with_gtts_fallback(text, auto_play)

def speak_with_gtts_fallback(text, auto_play=True):
    """Fallback TTS using gTTS - Streamlit Compatible"""
    try:
        clean_text = text.replace("*", "").replace("#", "").strip()
        if not clean_text:
            return False, None
            
        tts = gTTS(
            text=clean_text,
            lang="vi",
            slow=False,
            tld="com.au"
        )
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
            tts.save(tmp_file.name)
            temp_path = tmp_file.name
        
        if auto_play:
            # Display audio player with enhanced styling
            st.markdown('<div class="audio-container">', unsafe_allow_html=True)
            st.markdown("üéµ **Playing with Vietnamese gTTS:**")
            
            with open(temp_path, 'rb') as audio_file:
                audio_bytes = audio_file.read()
                st.audio(audio_bytes, format='audio/mp3', autoplay=True)
                
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Read audio data for return
        with open(temp_path, 'rb') as audio_file:
            audio_data = audio_file.read()
        
        # Cleanup
        os.unlink(temp_path)
        return True, audio_data
        
    except Exception as e:
        st.error(f"üîä L·ªói fallback TTS: {e}")
        return False, None

def create_downloadable_audio(text, voice_name="Kore", filename_prefix="zizou_audio"):
    """Create downloadable audio file with download link"""
    try:
        clean_text = text.replace("*", "").replace("#", "").strip()
        if not clean_text:
            return None
            
        voice_info = VOICE_OPTIONS.get(voice_name, VOICE_OPTIONS["Kore (Gemini TTS)"])
        
        if voice_info["model"] == "gtts":
            # Use gTTS
            tts = gTTS(text=clean_text, lang="vi", slow=False, tld="com.au")
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
                tts.save(tmp_file.name)
                with open(tmp_file.name, 'rb') as audio_file:
                    audio_data = audio_file.read()
                os.unlink(tmp_file.name)
            
            # Create download link
            b64 = base64.b64encode(audio_data).decode()
            filename = f"{filename_prefix}_Vietnamese.mp3"
            href = f'<a href="data:audio/mp3;base64,{b64}" download="{filename}" class="download-link">üì• Download Audio (Vietnamese gTTS)</a>'
        else:
            # Use Gemini TTS
            response = client.models.generate_content(
                model="gemini-2.5-flash-preview-tts",
                contents=clean_text,
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name=voice_info["voice"],
                            )
                        )
                    ),
                )
            )
            
            audio_data = response.candidates[0].content.parts[0].inline_data.data
            
            # Create download link
            b64 = base64.b64encode(audio_data).decode()
            filename = f"{filename_prefix}_{voice_info['voice']}.wav"
            href = f'<a href="data:audio/wav;base64,{b64}" download="{filename}" class="download-link">üì• Download Audio ({voice_info["voice"]})</a>'
        
        return audio_data, href
        
    except Exception as e:
        st.error(f"üîä L·ªói t·∫°o audio download: {e}")
        return None

def process_response_tone(response_text):
    """Add gentle tone markers to the response"""
    gentle_response = response_text.replace("*", "")
    return gentle_response

def encode_image_for_gemini(image):
    """Convert PIL Image to base64 for Gemini"""
    buffer = io.BytesIO()
    image.save(buffer, format="PNG")
    buffer.seek(0)
    return base64.b64encode(buffer.getvalue()).decode()

def analyze_image_with_zizou(image, user_question="", personality="professional"):
    """Analyze image using Gemini with selected personality"""
    try:
        # Convert image to base64
        image_data = encode_image_for_gemini(image)
        
        # Prepare prompt
        if user_question:
            prompt = f"H√£y ph√¢n t√≠ch h√¨nh ·∫£nh n√†y v√† tr·∫£ l·ªùi c√¢u h·ªèi: {user_question}"
        else:
            prompt = "H√£y m√¥ t·∫£ v√† ph√¢n t√≠ch h√¨nh ·∫£nh n√†y m·ªôt c√°ch chi ti·∫øt b·∫±ng ti·∫øng Vi·ªát."
        
        # Send to Gemini with image
        response = client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=[
                {
                    "role": "user",
                    "parts": [
                        {"text": prompt},
                        {
                            "inline_data": {
                                "mime_type": "image/png",
                                "data": image_data
                            }
                        }
                    ]
                }
            ],
            config=types.GenerateContentConfig(
                temperature=0.8,
                system_instruction=PERSONALITY_CONFIGS[personality]["prompt"]
            )
        )
        
        return response.text
        
    except Exception as e:
        return f"Xin l·ªói, c√≥ l·ªói khi ph√¢n t√≠ch h√¨nh ·∫£nh: {str(e)}"

def get_zizou_response(user_input, personality="professional"):
    """Generate response with selected personality"""
    try:
        response = client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=user_input,
            config=types.GenerateContentConfig(
                temperature=0.8,
                system_instruction=PERSONALITY_CONFIGS[personality]["prompt"]
            )
        )
        return response.text
        
    except Exception as e:
        print(f"API Error: {e}")
        return "Xin l·ªói b·∫°n, c√≥ ch√∫t v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t. B·∫°n c√≥ th·ªÉ th·ª≠ l·∫°i kh√¥ng?"

def analyze_file_content(file_content, file_name, user_question="", personality="professional"):
    """Analyze file content with Zizou"""
    try:
        prompt = f"Ph√¢n t√≠ch file '{file_name}' v·ªõi n·ªôi dung:\n\n{file_content[:8000]}"
        if len(file_content) > 8000:
            prompt += "\n\n[File b·ªã c·∫Øt ng·∫Øn do qu√° d√†i]"
        
        if user_question:
            prompt += f"\n\nC√¢u h·ªèi c·ª• th·ªÉ: {user_question}"
        
        response = get_zizou_response(prompt, personality)
        return process_response_tone(response)
        
    except Exception as e:
        return f"L·ªói ph√¢n t√≠ch file: {str(e)}"

def display_chat_history():
    """Display chat history with enhanced styling"""
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    if st.session_state.chat_history:
        st.markdown("### üìú L·ªãch s·ª≠ tr√≤ chuy·ªán")
        for i, (user_msg, bot_msg, timestamp) in enumerate(st.session_state.chat_history[-5:]):  # Show last 5
            st.markdown(f'<div class="user-message">üë§ <strong>B·∫°n ({timestamp}):</strong><br>{user_msg}</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="assistant-message">ü§ñ <strong>Zizou:</strong><br>{bot_msg}</div>', unsafe_allow_html=True)

def add_to_chat_history(user_msg, bot_msg):
    """Add conversation to chat history"""
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    timestamp = time.strftime("%H:%M")
    st.session_state.chat_history.append((user_msg, bot_msg, timestamp))
    
    # Keep only last 20 conversations
    if len(st.session_state.chat_history) > 20:
        st.session_state.chat_history = st.session_state.chat_history[-20:]

# Streamlit interface
def streamlit_interface():
    # Header with status indicator
    st.markdown("""
    <div style="text-align: center; margin-bottom: 2rem;">
        <h1>ü§ñ Zizou AI Assistant</h1>
        <div style="display: flex; align-items: center; justify-content: center; margin-top: 1rem;">
            <span class="status-online"></span>
            <span style="color: #ecf0f1; font-size: 1.1rem; font-weight: 500;">Online & Ready to Help</span>
        </div>
        <p style="color: #bdc3c7; margin-top: 10px;">üéµ Audio plays directly in your browser - Cloud compatible!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar configuration
    with st.sidebar:
        st.markdown('<div style="background: linear-gradient(45deg, #3498db, #2ecc71); padding: 20px; border-radius: 15px; margin-bottom: 20px; text-align: center;"><h2>üéõÔ∏è C·∫•u h√¨nh</h2></div>', unsafe_allow_html=True)
        
        # Personality selection
        st.markdown("### üé≠ T√≠nh c√°ch AI")
        personality = st.selectbox(
            "Ch·ªçn phong c√°ch tr·∫£ l·ªùi:",
            options=list(PERSONALITY_CONFIGS.keys()),
            format_func=lambda x: PERSONALITY_CONFIGS[x]["name"],
            index=0,
            help="Ch·ªçn c√°ch Zizou s·∫Ω tr·∫£ l·ªùi b·∫°n"
        )
        
        # Voice selection
        st.markdown("### üîä C·∫•u h√¨nh gi·ªçng n√≥i")
        voice_option = st.selectbox(
            "Ch·ªçn gi·ªçng n√≥i:",
            options=list(VOICE_OPTIONS.keys()),
            index=0,
            format_func=lambda x: f"{x}",
            help="Ch·ªçn gi·ªçng n√≥i cho Zizou"
        )
        
        # Display voice description
        st.info(f"‚ÑπÔ∏è {VOICE_OPTIONS[voice_option]['description']}")
        
        # Audio mode selection
        st.markdown("### üéµ Ch·∫ø ƒë·ªô √¢m thanh")
        audio_mode = st.radio(
            "Ch·ªçn c√°ch ph√°t √¢m thanh:",
            ["Auto-play (T·ª± ƒë·ªông)", "Manual play (Th·ªß c√¥ng)", "Download only (Ch·ªâ t·∫£i v·ªÅ)"],
            index=0,
            help="Auto-play c√≥ th·ªÉ b·ªã ch·∫∑n b·ªüi tr√¨nh duy·ªát"
        )
        
        # Enhanced stats with session info
        st.markdown("### üìä Th·ªëng k√™ phi√™n")
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Tin nh·∫Øn", len(st.session_state.chat_history), delta="üìù")
        with col2:
            st.metric("Tr·∫°ng th√°i", "Online", delta="‚úÖ")
        
        # System info
        st.markdown("### üåê Th√¥ng tin h·ªá th·ªëng")
        st.success("‚úÖ Streamlit Cloud Compatible")
        st.info("üîä Audio plays via st.audio()")
        st.info("üéØ No pygame dependencies")
        
        if audio_mode == "Auto-play (T·ª± ƒë·ªông)":
            st.warning("‚ö†Ô∏è Some browsers block autoplay")
        
        # Clear history button
        if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
            st.session_state.chat_history = []
            st.rerun()
    
    # Store configurations in session state
    st.session_state.personality = personality
    st.session_state.voice_option = voice_option
    st.session_state.audio_mode = audio_mode
    
    # Create tabs with enhanced styling
    tab1, tab2, tab3, tab4 = st.tabs(["üí¨ Chat", "üñºÔ∏è H√¨nh ·∫£nh", "üìÑ File", "üé§ Voice"])
    
    with tab1:
        st.markdown("### üí¨ Tr√≤ chuy·ªán v·ªõi Zizou")
        
        # Display chat history first
        display_chat_history()
        
        # Chat input
        user_input = st.text_area(
            "Nh·∫≠p c√¢u h·ªèi:", 
            height=120, 
            placeholder="H·ªèi Zizou b·∫•t c·ª© ƒëi·ªÅu g√¨... ü§î",
            key="chat_input"
        )
        
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            if st.button("üöÄ G·ª≠i c√¢u h·ªèi", type="primary", use_container_width=True):
                if user_input:
                    with st.spinner("ü§î Zizou ƒëang suy nghƒ©..."):
                        response = get_zizou_response(user_input, personality)
                        response = process_response_tone(response)
                        
                        # Add to chat history
                        add_to_chat_history(user_input, response)
                        
                        # Display current conversation in chat format
                        st.markdown(f'<div class="user-message">üë§ <strong>B·∫°n:</strong><br>{user_input}</div>', unsafe_allow_html=True)
                        st.markdown(f'<div class="assistant-message">ü§ñ <strong>Zizou ({PERSONALITY_CONFIGS[personality]["name"]}):</strong><br>{response}</div>', unsafe_allow_html=True)
                        
                        st.session_state.last_response = response
                        
                        # Auto-play if enabled
                        if audio_mode == "Auto-play (T·ª± ƒë·ªông)":
                            voice_info = VOICE_OPTIONS[voice_option]
                            with st.spinner("üéµ ƒêang ph√°t √¢m thanh..."):
                                if voice_info["model"] == "gtts":
                                    speak_with_gtts_fallback(response, auto_play=True)
                                else:
                                    speak_with_gemini_voice(response, voice_info["voice"], auto_play=True)
                else:
                    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√¢u h·ªèi!")
        
        with col2:
            if st.button("üîä Nghe c√¢u tr·∫£ l·ªùi", use_container_width=True):
                if hasattr(st.session_state, 'last_response'):
                    with st.spinner("üéµ ƒêang t·∫°o √¢m thanh..."):
                        voice_info = VOICE_OPTIONS[voice_option]
                        
                        if audio_mode == "Download only (Ch·ªâ t·∫£i v·ªÅ)":
                            # Create download link only
                            result = create_downloadable_audio(
                                st.session_state.last_response, 
                                voice_option,
                                "chat_response"
                            )
                            if result:
                                audio_data, download_link = result
                                st.markdown(download_link, unsafe_allow_html=True)
                        else:
                            # Play audio
                            if voice_info["model"] == "gtts":
                                success, _ = speak_with_gtts_fallback(st.session_state.last_response, auto_play=True)
                            else:
                                success, _ = speak_with_gemini_voice(st.session_state.last_response, voice_info["voice"], auto_play=True)
                            
                            if success:
                                st.success("‚úÖ ƒê√£ t·∫°o √¢m thanh!")
                            else:
                                st.error("‚ùå Kh√¥ng th·ªÉ t·∫°o √¢m thanh")
                else:
                    st.warning("‚ö†Ô∏è Ch∆∞a c√≥ c√¢u tr·∫£ l·ªùi ƒë·ªÉ ph√°t!")
        
        with col3:
            if st.button("üóëÔ∏è X√≥a", use_container_width=True):
                if 'last_response' in st.session_state:
                    del st.session_state.last_response
                st.rerun()
    
    with tab2:
        st.markdown("### üñºÔ∏è Ph√¢n t√≠ch h√¨nh ·∫£nh")
        
        uploaded_image = st.file_uploader(
            "üì∑ T·∫£i l√™n h√¨nh ·∫£nh:",
            type=['png', 'jpg', 'jpeg', 'gif', 'bmp'],
            help="Zizou s·∫Ω ph√¢n t√≠ch v√† gi·∫£i th√≠ch h√¨nh ·∫£nh"
        )
        
        image_question = st.text_input(
            "‚ùì C√¢u h·ªèi v·ªÅ h√¨nh ·∫£nh:",
            placeholder="VD: Trong h√¨nh n√†y c√≥ g√¨? Gi·∫£i th√≠ch chi ti·∫øt...",
            key="image_question"
        )
        
        if uploaded_image is not None:
            image = Image.open(uploaded_image)
            
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.image(image, caption="üì∑ H√¨nh ·∫£nh ƒë√£ t·∫£i l√™n", use_column_width=True)
            
            with col2:
                st.markdown('<div class="stColumn">', unsafe_allow_html=True)
                if st.button("üîç Ph√¢n t√≠ch h√¨nh ·∫£nh", type="primary", use_container_width=True):
                    with st.spinner("üîé Zizou ƒëang ph√¢n t√≠ch..."):
                        analysis = analyze_image_with_zizou(image, image_question, personality)
                        
                        st.markdown(f"**ü§ñ Ph√¢n t√≠ch c·ªßa Zizou ({PERSONALITY_CONFIGS[personality]['name']}):**")
                        st.write(analysis)
                        
                        st.session_state.last_image_response = analysis
                        
                        # Add to chat history
                        question_text = f"[Ph√¢n t√≠ch h√¨nh ·∫£nh] {image_question}" if image_question else "[Ph√¢n t√≠ch h√¨nh ·∫£nh]"
                        add_to_chat_history(question_text, analysis)
                
                if st.button("üîä Nghe ph√¢n t√≠ch", use_container_width=True):
                    if hasattr(st.session_state, 'last_image_response'):
                        with st.spinner("üéµ ƒêang t·∫°o √¢m thanh..."):
                            voice_info = VOICE_OPTIONS[voice_option]
                            
                            if audio_mode == "Download only (Ch·ªâ t·∫£i v·ªÅ)":
                                result = create_downloadable_audio(
                                    st.session_state.last_image_response, 
                                    voice_option,
                                    "image_analysis"
                                )
                                if result:
                                    audio_data, download_link = result
                                    st.markdown(download_link, unsafe_allow_html=True)
                            else:
                                if voice_info["model"] == "gtts":
                                    success, _ = speak_with_gtts_fallback(st.session_state.last_image_response, auto_play=True)
                                else:
                                    success, _ = speak_with_gemini_voice(st.session_state.last_image_response, voice_info["voice"], auto_play=True)
                                
                                if success:
                                    st.success("‚úÖ ƒê√£ ph√°t xong!")
                    else:
                        st.warning("‚ö†Ô∏è Ch∆∞a c√≥ ph√¢n t√≠ch ƒë·ªÉ ph√°t!")
                
                st.markdown('</div>', unsafe_allow_html=True)
    
    with tab3:
        st.markdown("### üìÑ Ph√¢n t√≠ch File")
        
        uploaded_files = st.file_uploader(
            "üìÑ T·∫£i l√™n file:",
            type=['txt', 'py', 'html', 'css', 'js', 'json', 'csv', 'md'],
            accept_multiple_files=True,
            help="Zizou c√≥ th·ªÉ ƒë·ªçc v√† ph√¢n t√≠ch code, text files"
        )
        
        file_question = st.text_input(
            "‚ùì C√¢u h·ªèi v·ªÅ file:",
            placeholder="VD: Code n√†y l√†m g√¨? T√≥m t·∫Øt n·ªôi dung...",
            key="file_question"
        )
        
        if uploaded_files:
            for uploaded_file in uploaded_files:
                st.markdown(f"""
                <div class="stColumn">
                    <h4>üìÑ File: {uploaded_file.name}</h4>
                </div>
                """, unsafe_allow_html=True)
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    try:
                        # Read file content
                        file_content = uploaded_file.read().decode("utf-8")
                        
                        # Show preview based on file type
                        if uploaded_file.name.endswith(('.py', '.html', '.css', '.js', '.json', '.md')):
                            language = uploaded_file.name.split('.')[-1]
                            if language == 'py':
                                language = 'python'
                            elif language == 'js':
                                language = 'javascript'
                            st.code(file_content[:1200] + "..." if len(file_content) > 12000 else file_content, language=language)
                        else:
                            st.text_area(f"N·ªôi dung preview:", file_content[:1000] + "..." if len(file_content) > 1000 else file_content, height=200, key=f"preview_{uploaded_file.name}")
                        
                        # Reset file pointer for analysis
                        uploaded_file.seek(0)
                        
                    except Exception as e:
                        st.error(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file: {e}")
                        continue
                
                with col2:
                    st.markdown('<div class="stColumn">', unsafe_allow_html=True)
                    st.markdown("**üîß Thao t√°c:**")
                    
                    if st.button(f"üîç Ph√¢n t√≠ch", key=f"analyze_{uploaded_file.name}", use_container_width=True):
                        with st.spinner(f"üìñ ƒêang ph√¢n t√≠ch {uploaded_file.name}..."):
                            try:
                                uploaded_file.seek(0)
                                file_content = uploaded_file.read().decode("utf-8")
                                analysis = analyze_file_content(file_content, uploaded_file.name, file_question, personality)
                                
                                st.markdown(f"**ü§ñ Ph√¢n t√≠ch c·ªßa Zizou ({PERSONALITY_CONFIGS[personality]['name']}):**")
                                st.write(analysis)
                                
                                st.session_state[f'file_response_{uploaded_file.name}'] = analysis
                                
                                # Add to chat history
                                question_text = f"[Ph√¢n t√≠ch file: {uploaded_file.name}] {file_question}" if file_question else f"[Ph√¢n t√≠ch file: {uploaded_file.name}]"
                                add_to_chat_history(question_text, analysis)
                                
                            except Exception as e:
                                st.error(f"‚ùå L·ªói: {e}")
                    
                    response_key = f'file_response_{uploaded_file.name}'
                    if st.button(f"üîä Nghe", key=f"voice_{uploaded_file.name}", use_container_width=True):
                        if response_key in st.session_state:
                            with st.spinner("üéµ ƒêang ph√°t..."):
                                voice_info = VOICE_OPTIONS[voice_option]
                                
                                if audio_mode == "Download only (Ch·ªâ t·∫£i v·ªÅ)":
                                    result = create_downloadable_audio(
                                        st.session_state[response_key], 
                                        voice_option,
                                        f"file_analysis_{uploaded_file.name}"
                                    )
                                    if result:
                                        audio_data, download_link = result
                                        st.markdown(download_link, unsafe_allow_html=True)
                                else:
                                    if voice_info["model"] == "gtts":
                                        success, _ = speak_with_gtts_fallback(st.session_state[response_key], auto_play=True)
                                    else:
                                        success, _ = speak_with_gemini_voice(st.session_state[response_key], voice_info["voice"], auto_play=True)
                                    
                                    if success:
                                        st.success("‚úÖ Ph√°t xong!")
                        else:
                            st.warning("‚ö†Ô∏è Ch∆∞a c√≥ ph√¢n t√≠ch!")
                    
                    st.markdown('</div>', unsafe_allow_html=True)
                
                st.markdown("---")
    
    with tab4:
        st.markdown("### üé§ Voice Chat")
        
        # Voice chat status
        if 'voice_chat_active' not in st.session_state:
            st.session_state.voice_chat_active = False
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if not st.session_state.voice_chat_active:
                if st.button("üé§ B·∫Øt ƒë·∫ßu Voice Chat", type="primary", use_container_width=True):
                    st.session_state.voice_chat_active = True
                    st.rerun()
            else:
                if st.button("‚èπÔ∏è D·ª´ng Voice Chat", type="secondary", use_container_width=True):
                    st.session_state.voice_chat_active = False
                    st.rerun()
        
        with col2:
            # Test voice button
            if st.button("üîä Test gi·ªçng n√≥i", use_container_width=True):
                voice_info = VOICE_OPTIONS[voice_option]
                test_text = f"Xin ch√†o! T√¥i l√† Zizou v·ªõi gi·ªçng n√≥i {voice_info['voice'] if voice_info['model'] != 'gtts' else 'ti·∫øng Vi·ªát'}. T√¥i s·∫µn s√†ng gi√∫p ƒë·ª° b·∫°n!"
                
                with st.spinner("üéµ ƒêang test gi·ªçng n√≥i..."):
                    if voice_info["model"] == "gtts":
                        success, _ = speak_with_gtts_fallback(test_text, auto_play=True)
                    else:
                        success, _ = speak_with_gemini_voice(test_text, voice_info["voice"], auto_play=True)
                    
                    if success:
                        st.success("‚úÖ Gi·ªçng n√≥i ho·∫°t ƒë·ªông t·ªët!")
                    else:
                        st.error("‚ùå C√≥ v·∫•n ƒë·ªÅ v·ªõi gi·ªçng n√≥i")
        
        with col3:
            # Voice settings
            if st.button("‚öôÔ∏è C√†i ƒë·∫∑t", use_container_width=True):
                st.info(f"""
                **üéõÔ∏è C·∫•u h√¨nh hi·ªán t·∫°i:**
                - T√≠nh c√°ch: {PERSONALITY_CONFIGS[personality]['name']}
                - Gi·ªçng n√≥i: {voice_option}
                - Ch·∫ø ƒë·ªô audio: {audio_mode}
                """)
        
        # Voice chat interface
        if st.session_state.voice_chat_active:
            st.markdown("""
            <div style="background: linear-gradient(45deg, rgba(46, 204, 113, 0.2), rgba(52, 152, 219, 0.2)); 
                        border-radius: 15px; padding: 20px; margin: 20px 0; text-align: center;">
                <div class="voice-wave">
                    <span></span><span></span><span></span><span></span>
                </div>
                <h3>üé§ Voice Chat ƒêang Ho·∫°t ƒê·ªông!</h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Manual voice input simulation
            st.markdown("**üéôÔ∏è Voice Input Simulation:**")
            voice_input = st.text_input("Nh·∫≠p tin nh·∫Øn (gi·∫£ l·∫≠p voice input):", key="voice_sim", placeholder="N√≥i ƒëi·ªÅu g√¨ ƒë√≥ v·ªõi Zizou...")
            
            if st.button("üó£Ô∏è G·ª≠i (gi·∫£ l·∫≠p voice)", key="send_voice", use_container_width=True):
                if voice_input:
                    with st.spinner("ü§î Zizou ƒëang nghe v√† tr·∫£ l·ªùi..."):
                        # Get response
                        response = get_zizou_response(voice_input, personality)
                        response = process_response_tone(response)
                        
                        # Add to chat history
                        add_to_chat_history(f"[Voice] {voice_input}", response)
                        
                        # Show conversation in chat bubbles
                        st.markdown(f'<div class="user-message">üë§ <strong>B·∫°n n√≥i:</strong><br>{voice_input}</div>', unsafe_allow_html=True)
                        st.markdown(f'<div class="assistant-message">ü§ñ <strong>Zizou ({PERSONALITY_CONFIGS[personality]["name"]}):</strong><br>{response}</div>', unsafe_allow_html=True)
                        
                        # Auto-play response with selected voice
                        with st.spinner(f"üéµ Zizou ƒëang n√≥i v·ªõi gi·ªçng {voice_option}..."):
                            voice_info = VOICE_OPTIONS[voice_option]
                            if voice_info["model"] == "gtts":
                                success, _ = speak_with_gtts_fallback(response, auto_play=True)
                            else:
                                success, _ = speak_with_gemini_voice(response, voice_info["voice"], auto_play=True)
                            
                            if success:
                                st.success("‚úÖ Zizou ƒë√£ tr·∫£ l·ªùi!")
                            else:
                                st.warning("‚ö†Ô∏è C√≥ v·∫•n ƒë·ªÅ v·ªõi √¢m thanh")
            
            # Enhanced info box
            st.markdown(f"""
            <div style="background: rgba(52, 152, 219, 0.1); border-radius: 15px; padding: 20px; margin: 20px 0;">
                <h4>üìã H∆∞·ªõng d·∫´n Voice Chat:</h4>
                <ul style="color: #ecf0f1;">
                    <li>üéØ Nh·∫≠p tin nh·∫Øn v√†o √¥ b√™n tr√™n (gi·∫£ l·∫≠p voice input)</li>
                    <li>üöÄ Click "G·ª≠i" ƒë·ªÉ Zizou tr·∫£ l·ªùi</li>
                    <li>üîä Zizou s·∫Ω t·ª± ƒë·ªông n√≥i c√¢u tr·∫£ l·ªùi v·ªõi gi·ªçng <strong>{voice_option}</strong></li>
                    <li>üé≠ Phong c√°ch tr·∫£ l·ªùi: <strong>{PERSONALITY_CONFIGS[personality]['name']}</strong></li>
                    <li>üéµ Ch·∫ø ƒë·ªô audio: <strong>{audio_mode}</strong></li>
                </ul>
                
                <h4>üí° ƒê·ªÉ s·ª≠ d·ª•ng microphone th·ª±c:</h4>
                <p style="color: #bdc3c7;">C·∫ßn c√†i ƒë·∫∑t th√™m c√°c th∆∞ vi·ªán: <code>pip install pyaudio speechrecognition</code></p>
                <p style="color: #bdc3c7;">V√† ch·∫°y script trong terminal v·ªõi microphone support</p>
                
                <h4>üéµ {voice_option} Features:</h4>
                <p style="color: #ecf0f1;">{VOICE_OPTIONS[voice_option]['description']}</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            # Voice chat info when inactive
            st.markdown("""
            <div style="background: rgba(52, 73, 94, 0.3); border-radius: 15px; padding: 30px; text-align: center;">
                <h3>üé§ Voice Chat Features</h3>
                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin-top: 20px;">
                    <div style="background: rgba(46, 204, 113, 0.1); padding: 15px; border-radius: 10px;">
                        <h4>üéØ Nh·∫≠n di·ªán gi·ªçng n√≥i</h4>
                        <p>H·ªó tr·ª£ ti·∫øng Vi·ªát v√† nhi·ªÅu ng√¥n ng·ªØ kh√°c</p>
                    </div>
                    <div style="background: rgba(52, 152, 219, 0.1); padding: 15px; border-radius: 10px;">
                        <h4>üîä Multi-Voice TTS</h4>
                        <p>5+ gi·ªçng n√≥i AI ch·∫•t l∆∞·ª£ng cao</p>
                    </div>
                    <div style="background: rgba(155, 89, 182, 0.1); padding: 15px; border-radius: 10px;">
                        <h4>üé≠ ƒêa t√≠nh c√°ch</h4>
                        <p>4 phong c√°ch tr·∫£ l·ªùi kh√°c nhau</p>
                    </div>
                    <div style="background: rgba(230, 126, 34, 0.1); padding: 15px; border-radius: 10px;">
                        <h4>ü§ñ AI th√¥ng minh</h4>
                        <p>ƒê·ªëi tho·∫°i t·ª± nhi√™n v·ªõi Gemini AI</p>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # Requirements section
            with st.expander("üîß Y√™u c·∫ßu k·ªπ thu·∫≠t", expanded=False):
                st.code("""
# C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt (Streamlit Cloud compatible):
pip install gtts google-generativeai speechrecognition streamlit pillow wave

# Ch·∫°y ·ª©ng d·ª•ng:
streamlit run zizou_app.py

# L∆∞u √Ω: 
# - Kh√¥ng c·∫ßn pygame (ƒë√£ thay b·∫±ng st.audio)
# - Ho·∫°t ƒë·ªông t·ªët tr√™n Streamlit Cloud
# - Audio ƒë∆∞·ª£c ph√°t qua tr√¨nh duy·ªát
                """, language="bash")


# Console version for real voice chat (optional)
def main_console():
    """Console version with real microphone support - requires pyaudio"""
    print("ü§ñ Zizou ƒëang kh·ªüi ƒë·ªông v·ªõi ƒëa gi·ªçng n√≥i AI... Xin ch√†o b·∫°n!")
    print("üí° Tip: N√≥i 't·∫°m bi·ªát' ho·∫∑c 'bye' ƒë·ªÉ tho√°t")
    print("üîä Voice: S·ª≠ d·ª•ng Gemini AI voices ch·∫•t l∆∞·ª£ng cao")
    print("‚ö†Ô∏è  L∆∞u √Ω: Version n√†y c·∫ßn microphone v√† pyaudio")
    
    try:
        import pyaudio
    except ImportError:
        print("‚ùå C·∫ßn c√†i ƒë·∫∑t: pip install pyaudio")
        print("üí° Ho·∫∑c s·ª≠ d·ª•ng Streamlit version: streamlit run zizou_app.py")
        return
    
    # Voice selection in console
    print("\nüéµ Ch·ªçn gi·ªçng n√≥i:")
    voices = list(VOICE_OPTIONS.keys())
    for i, voice in enumerate(voices):
        print(f"{i+1}. {voice} - {VOICE_OPTIONS[voice]['description']}")
    
    try:
        voice_choice = int(input("Ch·ªçn gi·ªçng n√≥i (1-5): ")) - 1
        if 0 <= voice_choice < len(voices):
            selected_voice = voices[voice_choice]
            print(f"‚úÖ ƒê√£ ch·ªçn: {selected_voice}")
        else:
            selected_voice = "Kore (Gemini TTS)"
            print(f"‚ö†Ô∏è L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh: {selected_voice}")
    except:
        selected_voice = "Kore (Gemini TTS)"
        print(f"‚ö†Ô∏è S·ª≠ d·ª•ng gi·ªçng m·∫∑c ƒë·ªãnh: {selected_voice}")
    
    # Personality selection
    print("\nüé≠ Ch·ªçn t√≠nh c√°ch:")
    personalities = list(PERSONALITY_CONFIGS.keys())
    for i, personality in enumerate(personalities):
        print(f"{i+1}. {PERSONALITY_CONFIGS[personality]['name']}")
    
    try:
        personality_choice = int(input("Ch·ªçn t√≠nh c√°ch (1-4): ")) - 1
        if 0 <= personality_choice < len(personalities):
            selected_personality = personalities[personality_choice]
            print(f"‚úÖ ƒê√£ ch·ªçn: {PERSONALITY_CONFIGS[selected_personality]['name']}")
        else:
            selected_personality = "professional"
            print(f"‚ö†Ô∏è L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh: Chuy√™n nghi·ªáp")
    except:
        selected_personality = "professional"
        print(f"‚ö†Ô∏è S·ª≠ d·ª•ng t√≠nh c√°ch m·∫∑c ƒë·ªãnh: Chuy√™n nghi·ªáp")
    
    print(f"\nüöÄ B·∫Øt ƒë·∫ßu voice chat v·ªõi {selected_voice} - {PERSONALITY_CONFIGS[selected_personality]['name']}")
    print("üìå Streamlit version kh√¥ng c·∫ßn console - ch·∫°y: streamlit run zizou_app.py")
    
    while True:
        try:
            with speech_recognition.Microphone() as mic:
                robot_ear.adjust_for_ambient_noise(mic, duration=1)
                print("üé§ Zizou: T√¥i ƒëang l·∫Øng nghe...")
                print("‚è∞ B·∫°n c√≥ 10s ƒë·ªÉ n√≥i!")
                audio = robot_ear.listen(mic, timeout=10, phrase_time_limit=15)
        
            print("ü§î ƒêang x·ª≠ l√Ω...")
                
            try:
                you = robot_ear.recognize_google(audio, language="vi-VN")
            except speech_recognition.UnknownValueError:
                error_msg = "üòÖ T√¥i kh√¥ng nghe r√µ. N√≥i l·∫°i ƒë∆∞·ª£c kh√¥ng?"
                print(f"ü§ñ Zizou: {error_msg}")
                # Console version would need pygame or other audio library here
                # For Streamlit Cloud compatibility, we removed pygame
                continue
            except speech_recognition.RequestError:
                error_msg = "üîß C√≥ v·∫•n ƒë·ªÅ k·∫øt n·ªëi. Th·ª≠ l·∫°i nh√©."
                print(f"ü§ñ Zizou: {error_msg}")
                continue
            
            if not you:
                continue
                
            print(f"üë§ B·∫°n: {you}")
            
            # Exit conditions
            if "t·∫°m bi·ªát" in you.lower() or "bye" in you.lower():
                goodbye_msg = "T·∫°m bi·ªát! H·∫πn g·∫∑p l·∫°i! üåü"
                print(f"ü§ñ Zizou: {goodbye_msg}")
                break
            
            # Generate response
            robot_brain = get_zizou_response(you, selected_personality)
            robot_brain = process_response_tone(robot_brain)
            
            print(f"ü§ñ Zizou ({PERSONALITY_CONFIGS[selected_personality]['name']}): {robot_brain}")
            print("üí° Audio playback requires Streamlit interface")
            
        except KeyboardInterrupt:
            print("\nüëã T·∫°m bi·ªát!")
            break
        except Exception as e:
            print(f"‚ùå L·ªói: {e}")


if __name__ == "__main__":
    try:
        # Check if running in Streamlit
        streamlit_interface()
    except:
        # Run console version (limited functionality without pygame)
        print("üéØ Khuy·∫øn ngh·ªã: Ch·∫°y v·ªõi Streamlit ƒë·ªÉ c√≥ ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng")
        print("üìå Command: streamlit run zizou_app.py")
        main_console()
